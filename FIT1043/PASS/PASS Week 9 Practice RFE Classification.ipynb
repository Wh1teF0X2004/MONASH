{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fbe1de9",
   "metadata": {},
   "source": [
    "# Last Python stretch: Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "611f89d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "## for the sake of readability \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d1084",
   "metadata": {},
   "source": [
    "# Briefthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea8b22",
   "metadata": {},
   "source": [
    "Pipeline is something new and worth looking at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b37147",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32be0f5",
   "metadata": {},
   "source": [
    "# RFE : Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a94066",
   "metadata": {},
   "source": [
    "Let's first look at RFE for classification, specifically DecisionTreeClassifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1b154",
   "metadata": {},
   "source": [
    "## Import the necessary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28bb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate RFE for classification\n",
    "from numpy import mean, std\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#impt \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#for evaluation sake only\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c3e99c",
   "metadata": {},
   "source": [
    "Something to note in this approach are DecisionTreeClassifier and Pipeline. \n",
    "\n",
    "the last 2 import is not necessary ( it is just for demo purpose ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c5cd",
   "metadata": {},
   "source": [
    "## Get your data (in my case is to fake it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "196a65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2b88c",
   "metadata": {},
   "source": [
    "## Here we create the Pipeline for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e85cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create pipeline\n",
    "\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c20f1",
   "metadata": {},
   "source": [
    "## Extra: Evaluating it (this is good for justification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33b4a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.885 (0.035)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a44da",
   "metadata": {},
   "source": [
    "It is ok if your accuracy differs from mine. The data generated randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9902467",
   "metadata": {},
   "source": [
    "## Prediction with RFE result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "611e3272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;s&#x27;,\n",
       "                 RFE(estimator=DecisionTreeClassifier(),\n",
       "                     n_features_to_select=5)),\n",
       "                (&#x27;m&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;s&#x27;,\n",
       "                 RFE(estimator=DecisionTreeClassifier(),\n",
       "                     n_features_to_select=5)),\n",
       "                (&#x27;m&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">s: RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('s',\n",
       "                 RFE(estimator=DecisionTreeClassifier(),\n",
       "                     n_features_to_select=5)),\n",
       "                ('m', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction with an RFE pipeline\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# fit the model on all available data\n",
    "pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48d22ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# test out\n",
    "testData = [[2.56999479,-0.13019997,3.16075093,-4.35936352,-1.61271951,-1.39352057,-2.48924933,-1.93094078,3.26130366,2.05692145]]\n",
    "ypred = pipeline.predict(testData)\n",
    "print('Predicted Class: %d' % (ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c612ed",
   "metadata": {},
   "source": [
    "# Revisit RFE : Regression (also extra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187996e9",
   "metadata": {},
   "source": [
    "Something bit different to look at is the Pipeline. Let's create Regression data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f55d9099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0925cd",
   "metadata": {},
   "source": [
    "## Let's just test whether it is accurate to use RFE or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9ebb6d",
   "metadata": {},
   "source": [
    "Like the previous section, we now can look at the accuracy of it. For this, we can make use MAE --> Mean Absolute Error as a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ec02f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -27.263 (2.810)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5)\n",
    "model = DecisionTreeRegressor()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee781f3d",
   "metadata": {},
   "source": [
    "Result may vary due to the nature of the algorithm. This is super EXTRA but You may refer to this for better understanding of WHY AM I GETTING DIFFERENT RESULT in ML T vT  https://machinelearningmastery.com/different-results-each-time-in-machine-learning/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5)\n",
    "model = DecisionTreeRegressor()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# fit the model \n",
    "pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d5693cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: -84.288\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "testData = [[-2.02220122,0.31563495,0.82797464,-0.30620401,0.16003707,-1.44411381,0.87616892,-0.50446586,0.23009474,0.76201118]]\n",
    "ypred = pipeline.predict(testData)\n",
    "print('Predicted: %.3f' % (ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3460d",
   "metadata": {},
   "source": [
    "# What is the best number of feature to select?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cec3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">2 0.718 (0.041)\n",
      ">3 0.822 (0.035)\n",
      ">4 0.877 (0.030)\n",
      ">5 0.884 (0.031)\n",
      ">6 0.891 (0.029)\n",
      ">7 0.887 (0.031)\n",
      ">8 0.881 (0.031)\n",
      ">9 0.884 (0.023)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore the number of selected features for RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(2, 10):\n",
    "        rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=i)\n",
    "        model = DecisionTreeClassifier()\n",
    "        models[str(i)] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "    \n",
    "    \n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67007fd",
   "metadata": {},
   "source": [
    "In this case, we can see that performance improves as the number of features increase and perhaps peaks around 5-to-9 as we might expect, given that only five features are relevant to the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39787edc",
   "metadata": {},
   "source": [
    "# Automatically Select the Number of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e760406",
   "metadata": {},
   "source": [
    "It is actually possible to let the ML do everything for us. We can make use of a class call RFECV https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c35708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example code\n",
    "# automatically choose the number of features\n",
    "# rfe = RFECV(estimator=DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09dc3a",
   "metadata": {},
   "source": [
    "The RFECV is configured just like the RFE class regarding the choice of the algorithm that is wrapped. Additionally, the minimum number of features to be considered can be specified via the “min_features_to_select” argument (defaults to 1) and we can also specify the type of cross-validation and scoring to use via the “cv” (defaults to 5) and “scoring” arguments (uses accuracy for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fae1e096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.880 (0.025)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# create pipeline\n",
    "rfe = RFECV(estimator=DecisionTreeClassifier())\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04287b",
   "metadata": {},
   "source": [
    "# Which Features Were Selected\n",
    "When using RFE, we may be interested to know which features were selected and which were removed.\n",
    "\n",
    "This can be achieved by reviewing the attributes of the fit RFE object (or fit RFECV object). The “support_” attribute reports true or false as to which features in order of column index were included and the “ranking_” attribute reports the relative ranking of features in the same order.\n",
    "\n",
    "The example below fits an RFE model on the whole dataset and selects five features, then reports each feature column index (0 to 9), whether it was selected or not (True or False), and the relative feature ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f55d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 0, Selected False, Rank: 5.000\n",
      "Column: 1, Selected False, Rank: 4.000\n",
      "Column: 2, Selected True, Rank: 1.000\n",
      "Column: 3, Selected True, Rank: 1.000\n",
      "Column: 4, Selected True, Rank: 1.000\n",
      "Column: 5, Selected False, Rank: 6.000\n",
      "Column: 6, Selected True, Rank: 1.000\n",
      "Column: 7, Selected False, Rank: 3.000\n",
      "Column: 8, Selected True, Rank: 1.000\n",
      "Column: 9, Selected False, Rank: 2.000\n"
     ]
    }
   ],
   "source": [
    "# report which features were selected by RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# define RFE\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "# fit RFE\n",
    "rfe.fit(X, y)\n",
    "# summarize all features\n",
    "for i in range(X.shape[1]):\n",
    "\tprint('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9b2c1",
   "metadata": {},
   "source": [
    "# VERY EXTRA: Let's look at the base algorithm and test different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46a24f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.891 (0.030)\n",
      ">per 0.846 (0.039)\n",
      ">cart 0.890 (0.034)\n",
      ">rf 0.864 (0.034)\n",
      ">gbm 0.889 (0.031)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# explore the algorithm wrapped by RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # lr\n",
    "    rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['lr'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # perceptron\n",
    "    rfe = RFE(estimator=Perceptron(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['per'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # cart\n",
    "    rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['cart'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # rf\n",
    "    rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['rf'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # gbm\n",
    "    rfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=5)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['gbm'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
