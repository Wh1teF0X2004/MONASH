{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b834463",
   "metadata": {},
   "source": [
    "<div style= \"text-align: right\">\n",
    "    <p style= \"text-align: right; font-weight: bold; font-size: x-large;\">FIT3182 Big Data Management and Processing</p>\n",
    "    <p style= \"text-align: right; font-weight: bold; font-size: large;\">Assignment 2</p>\n",
    "    <p style= \"text-align: right\">Foo Kai Yan</p>\n",
    "    <p style= \"text-align: right\">kfoo0012@student.monash.edu<br><br><i>33085625<br><br><i>5<sup>th</sup> May 2024</i></p>\n",
    "<div>\n",
    "<hr style=\"border-color: black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a88376",
   "metadata": {},
   "source": [
    "## Student Statement\n",
    "The assignment was completed with the assistance of some code obtained from seminar/tutorial/lab/applied class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce768c0",
   "metadata": {},
   "source": [
    "### Installing PyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5bc036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.8/site-packages (4.3.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from pymongo) (2.3.0)\n",
      "Requirement already satisfied: pygeohash in /opt/conda/lib/python3.8/site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo\n",
    "!pip install pygeohash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c6d7f",
   "metadata": {},
   "source": [
    "### Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f69ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import pygeohash as pgh\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf # spark\n",
    "from pyspark.streaming import StreamingContext # spark streaming\n",
    "from pyspark.sql.functions import col, split, element_at, when"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791d2db",
   "metadata": {},
   "source": [
    "### Check working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07df9969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/student/kfoo0012'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb931ae4",
   "metadata": {},
   "source": [
    "### Set os environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f01459",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.3.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f953f",
   "metadata": {},
   "source": [
    "### Set host ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89789e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hostip obtained using `ipconfig` command in command prompt\n",
    "hostip = \"192.168.68.58\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61252c",
   "metadata": {},
   "source": [
    "### Streaming Application Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada853fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Climate, Hotspot_AQUA, Hotspot_TERRA\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]') # local[*] MEANS you are using all the available processors\n",
    "    .appName('Streaming Climate Data')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc59567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is basically connecting to kafka server\n",
    "topic_stream_df = (\n",
    "    spark.readStream.format('kafka') # 'kafka' because u are receiving from kafka\n",
    "    .option('kafka.bootstrap.servers', f'{hostip}:9092')\n",
    "    .option('subscribe', topic)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c6972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sdf = topic_stream_df.select('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "35284526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addtoDatabase_OLD(batch_df, batch_id):\n",
    "    all_data = batch_df.collect()  # Returns all elements as an array\n",
    "    # Send stream data to be transformed & analysed\n",
    "    producer_data = [row.asDict() for row in all_data]\n",
    "#     new_data = process_producer_data(data)\n",
    "    for eachdata in range(len(producer_data)): \n",
    "        temp_var = producer_data[eachdata].get('value')\n",
    "        # print(\"eachdata: \", eachdata)\n",
    "        # Convert byte array to string\n",
    "        newdata = temp_var.decode('utf-8')\n",
    "        # Convert string to JSON\n",
    "        produced_data = json.loads(newdata)\n",
    "        producer_data[eachdata] = produced_data\n",
    "        print(\"produced_data: \", producer_data)\n",
    "\n",
    "def addtoDatabase_old(batch_df, batch_id):\n",
    "    all_data = batch_df.collect()  # Returns all elements as an array\n",
    "    # Send stream data to be transformed & analysed\n",
    "    producer_data = [row.asDict() for row in all_data]\n",
    "\n",
    "    for eachdata in range(len(producer_data)):\n",
    "        # Check if 'value' key exists and is a bytearray\n",
    "        if 'value' in producer_data[eachdata] and isinstance(producer_data[eachdata]['value'], bytearray):\n",
    "            # Convert byte array to string\n",
    "            newdata = producer_data[eachdata]['value'].decode('utf-8')\n",
    "            # Convert string to JSON\n",
    "            produced_data = json.loads(newdata)\n",
    "            producer_data[eachdata] = produced_data\n",
    "        # If 'value' is not a bytearray, keep the original dictionary\n",
    "\n",
    "    print(\"produced_data: \", producer_data)\n",
    "    \n",
    "    for producer in producer_data:\n",
    "        producer_id = producer[\"producer_id\"]\n",
    "\n",
    "        climate_record = {}\n",
    "        aqua_hotspots_record = []\n",
    "        terra_hotspots_record = []\n",
    "\n",
    "        # Sort data depending on the producer_id information\n",
    "        if producer_id == \"producer1_climate\":\n",
    "            climate_record = producer\n",
    "            print(\"climate record\", climate_record)\n",
    "        elif producer_id == \"producer2_hotspot_aqua\":\n",
    "            aqua_hotspots_record.append(producer)\n",
    "            print(\"aqua_hotspots_record\", aqua_hotspots_record)\n",
    "        elif producer_id == \"producer3_hotspot_terra\":\n",
    "            terra_hotspots_record.append(producer)\n",
    "            print(\"terra_hotspots_record\", terra_hotspots_record)\n",
    "            \n",
    "        hotspots = []\n",
    "        \n",
    "        \n",
    "            \n",
    "        # Get Climate longitude and latitude\n",
    "        climate_latitude = climate_record.get(\"latitude\")\n",
    "        climate_longitude = climate_record.get(\"longitude\") \n",
    "\n",
    "#         print(\"climate_latitude: \", climate_latitude)\n",
    "#         print(\"climate_longitude: \", climate_longitude)\n",
    "        \n",
    "        # Process aqua_hotspots_record\n",
    "        for each_record in aqua_hotspots_record:\n",
    "            #if geohash_proximity(each_record, climate_record):\n",
    "            if (pgh.encode(each_record[\"longitude\"], each_record[\"latitude\"], precision = 3) == pgh.encode(climate_record.get(\"longitude\"), climate_record.get(\"latitude\"), precision = 3)):\n",
    "                #each_record[\"date\"] = climate_record.get(\"date\")\n",
    "                hotspots.append(each_record)\n",
    "                print(\"hotspot\", hotspots)\n",
    "\n",
    "def addtoDatabase(batch_df, batch_id): # NO ERROR OUH YEAAA\n",
    "    all_data = batch_df.collect()  # Returns all elements as an array\n",
    "    producer_data = [row.asDict() for row in all_data]\n",
    "\n",
    "    climate_record = [] #{}\n",
    "    aqua_hotspots_record = []\n",
    "    terra_hotspots_record = []\n",
    "    hotspots = []\n",
    "\n",
    "    for eachdata in range(len(producer_data)):\n",
    "        # Check if 'value' key exists and is a bytearray\n",
    "        if 'value' in producer_data[eachdata] and isinstance(producer_data[eachdata]['value'], bytearray):\n",
    "            # Convert byte array to string and then to JSON\n",
    "            newdata = producer_data[eachdata]['value'].decode('utf-8')\n",
    "            produced_data = json.loads(newdata)\n",
    "            producer_data[eachdata] = produced_data\n",
    "\n",
    "    for producer in producer_data:\n",
    "        producer_id = producer[\"producer_id\"]\n",
    "\n",
    "#         climate_record = {}\n",
    "#         aqua_hotspots_record = []\n",
    "#         terra_hotspots_record = []\n",
    "\n",
    "        # Sort data depending on the producer_id information\n",
    "        if producer_id == \"producer1_climate\":\n",
    "            climate_record.append(producer)\n",
    "            # print(\"climate record\", climate_record)\n",
    "        elif producer_id == \"producer2_hotspot_aqua\":\n",
    "            aqua_hotspots_record.append(producer)\n",
    "            # print(\"aqua_hotspots_record\", aqua_hotspots_record)\n",
    "        elif producer_id == \"producer3_hotspot_terra\":\n",
    "            terra_hotspots_record.append(producer)\n",
    "            # print(\"terra_hotspots_record\", terra_hotspots_record)\n",
    "\n",
    "    # If there are no climate records, skip processing this batch\n",
    "    # Check if the dictionary is empty\n",
    "    if len(climate_record) == 1:\n",
    "        climate_record = climate_record\n",
    "    elif len(climate_record) > 1:\n",
    "        climate_record = climate_record[0]\n",
    "    else:\n",
    "        # print(\"No climate record present in this batch. Skipping...\")\n",
    "        return  # Exit the function\n",
    "\n",
    "    # If there is a climate record, continue processing\n",
    "    # ... rest of your code to process the records ...\n",
    "\n",
    "#     print(\"Climate records:\", climate_record)\n",
    "#     print(\"Aqua hotspots records:\", aqua_hotspots_record)\n",
    "#     print(\"Terra hotspots records:\", terra_hotspots_record)\n",
    "    # Further processing can be done here, such as combining data or storing in a database\n",
    "\n",
    "    # Process terra_hotspots_record\n",
    "    print(\"out loop\")\n",
    "    for each_record in terra_hotspots_record:\n",
    "        print(\"in loop terra\")\n",
    "        if geohash_proximity(each_record, climate_record):\n",
    "            #each_record[\"date\"] = climate_record.get(\"date\")\n",
    "            hotspots.append(each_record)\n",
    "            print(\"hotspot\", hotspots)\n",
    "            \n",
    "    for each_record in aqua_hotspots_record:\n",
    "        print(\"in loop aqua\")\n",
    "        if geohash_proximity(each_record, climate_record):\n",
    "            #each_record[\"date\"] = climate_record.get(\"date\")\n",
    "            hotspots.append(each_record)\n",
    "            print(\"hotspot\", hotspots)\n",
    "            \n",
    "    # Analyse hotspots data, find if any are close by & merge\n",
    "    new_hotspots_record = hotspots\n",
    "    # Merge hotspots with climate depending if close & label if natural or other\n",
    "    new_climate_record = process_climate(climate_record, new_hotspots_record)\n",
    "            \n",
    "    return hotspots\n",
    "\n",
    "# Check proximity based on geohash, precision 3\n",
    "def geohash_proximity(record, climate):\n",
    "    record_geohash = pgh.encode(record[\"longitude\"], record[\"latitude\"], precision = 3)\n",
    "    climate_geohash = pgh.encode(climate[0][\"longitude\"], climate[0][\"latitude\"], precision = 3)\n",
    "    return record_geohash == climate_geohash\n",
    "\n",
    "    # Only save data with contents\n",
    "#     if len(new_data) > 1:\n",
    "\n",
    "#         client = MongoClient(f'mongodb://{hostip}:27017/')\n",
    "\n",
    "#         db = client.fit3182_assignment_db\n",
    "#         climate_collection = db.climate_collection\n",
    "\n",
    "#         # Insert climate data into database\n",
    "#         climate_collection.insert_one(new_data)\n",
    "#         pprint(new_data)\n",
    "\n",
    "#         client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "62d4acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_writer = (\n",
    "    data_sdf\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    # collect data for 10 seconds\n",
    "    .trigger(processingTime='10 seconds')\n",
    "    # each batch of 10 seconds will run func\n",
    "    .foreachBatch(addtoDatabase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "abc79ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate records: [{'latitude': -37.329, 'longitude': 143.136, 'air_temperature_celcius': 21.0, 'relative_humidity': 47.0, 'windspeed_knots': 13.2, 'max_wind_speed': 20.0, 'GHI_w/m2': 185.0, 'precipitation_flag': 'I', 'precipitation': 0.0, 'latest_date': '2025-04-14T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "Climate records: [{'latitude': -36.2669, 'longitude': 143.1906, 'air_temperature_celcius': 12.0, 'relative_humidity': 42.7, 'windspeed_knots': 10.0, 'max_wind_speed': 15.9, 'GHI_w/m2': 109.0, 'precipitation_flag': 'G', 'precipitation': 0.01, 'latest_date': '2025-04-15T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "in loop\n",
      "hotspot [{'latitude': -36.4195, 'longitude': 141.2093, 'confidence': 60.0, 'surface_temperature_celcius': 42.0, 'created_time': '06:26:48', 'producer_id': 'producer3_hotspot_terra'}]\n",
      "Climate records: [{'latitude': -37.013, 'longitude': 141.5355, 'air_temperature_celcius': 10.0, 'relative_humidity': 44.1, 'windspeed_knots': 7.3, 'max_wind_speed': 12.0, 'GHI_w/m2': 90.0, 'precipitation_flag': 'G', 'precipitation': 0.39, 'latest_date': '2025-04-16T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "Climate records: [{'latitude': -37.238, 'longitude': 141.145, 'air_temperature_celcius': 8.0, 'relative_humidity': 41.6, 'windspeed_knots': 8.3, 'max_wind_speed': 15.9, 'GHI_w/m2': 73.0, 'precipitation_flag': 'G', 'precipitation': 0.24, 'latest_date': '2025-04-17T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "in loop\n",
      "Climate records: [{'latitude': -37.4661, 'longitude': 143.2419, 'air_temperature_celcius': 14.0, 'relative_humidity': 48.2, 'windspeed_knots': 9.1, 'max_wind_speed': 15.0, 'GHI_w/m2': 122.0, 'precipitation_flag': 'G', 'precipitation': 0.0, 'latest_date': '2025-04-18T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "hotspot [{'latitude': -36.6368, 'longitude': 144.8346, 'confidence': 77.0, 'surface_temperature_celcius': 50.0, 'created_time': '06:26:48', 'producer_id': 'producer3_hotspot_terra'}]\n",
      "in loop\n",
      "Climate records: [{'latitude': -37.69, 'longitude': 143.605, 'air_temperature_celcius': 14.0, 'relative_humidity': 45.7, 'windspeed_knots': 9.2, 'max_wind_speed': 15.9, 'GHI_w/m2': 124.0, 'precipitation_flag': 'I', 'precipitation': 0.0, 'latest_date': '2025-04-19T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "hotspot [{'latitude': -37.662, 'longitude': 142.6505, 'confidence': 75.0, 'surface_temperature_celcius': 49.0, 'created_time': '06:26:48', 'producer_id': 'producer3_hotspot_terra'}]\n",
      "Climate records: [{'latitude': -37.858, 'longitude': 143.428, 'air_temperature_celcius': 14.0, 'relative_humidity': 49.5, 'windspeed_knots': 6.0, 'max_wind_speed': 12.0, 'GHI_w/m2': 121.0, 'precipitation_flag': 'G', 'precipitation': 0.0, 'latest_date': '2025-04-20T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "hotspot [{'latitude': -37.8429, 'longitude': 143.8366, 'confidence': 100.0, 'surface_temperature_celcius': 88.0, 'created_time': '06:26:48', 'producer_id': 'producer3_hotspot_terra'}]\n",
      "in loop\n",
      "hotspot [{'latitude': -37.8429, 'longitude': 143.8366, 'confidence': 100.0, 'surface_temperature_celcius': 88.0, 'created_time': '06:26:48', 'producer_id': 'producer3_hotspot_terra'}, {'latitude': -37.9538, 'longitude': 143.1487, 'confidence': 62.0, 'surface_temperature_celcius': 41.0, 'created_time': '06:26:48', 'producer_id': 'producer3_hotspot_terra'}]\n",
      "Climate records: [{'latitude': -37.382, 'longitude': 149.341, 'air_temperature_celcius': 18.0, 'relative_humidity': 53.6, 'windspeed_knots': 7.2, 'max_wind_speed': 15.0, 'GHI_w/m2': 150.0, 'precipitation_flag': 'I', 'precipitation': 0.0, 'latest_date': '2025-04-21T00:00:00', 'producer_id': 'producer1_climate'}]\n",
      "out loop\n",
      "in loop\n",
      "hotspot [{'latitude': -36.6707, 'longitude': 143.8452, 'confidence': 78.0, 'surface_temperature_celcius': 51.0, 'created_time': '06:26:48', 'producer_id': 'producer3_hotspot_terra'}]\n",
      "in loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted by CTRL-C. Stopping query.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    query = db_writer.start()\n",
    "    query.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted by CTRL-C. Stopping query.')\n",
    "finally:\n",
    "    query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debcf08e",
   "metadata": {},
   "source": [
    "client = MongoClient(f'mongodb://{hostip}:27017/')\n",
    "db = client.fit3182_assignment_db\n",
    "cursor = db.climate_collection.find({})\n",
    "\n",
    "for document in cursor:\n",
    "    pprint(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38921b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check proximity based on geohash, precision 5\n",
    "def geohash_proximity_5(record, climate):\n",
    "    record_geohash = pgh.encode(record.get(\"longitude\"), record.get(\"latitude\"), precision = 5)\n",
    "    climate_geohash = pgh.encode(climate.get(\"longitude\"), climate.get(\"latitude\"), precision = 5)\n",
    "    return record_geohash == climate_geohash\n",
    "\n",
    "# Check proximity based on geohash, precision 3\n",
    "def geohash_proximity(record, climate):\n",
    "    record_geohash = pgh.encode(record.get(\"longitude\"), record.get(\"latitude\"), precision = 3)\n",
    "    climate_geohash = pgh.encode(climate.get(\"longitude\"), climate.get(\"latitude\"), precision = 3)\n",
    "    return record_geohash == climate_geohash\n",
    "\n",
    "def process_producer_data(producer_data):\n",
    "    print(\"producer_data: \", producer_data)\n",
    "    # Initialize empty lists for aqua_hotspots_record, terra_hotspots_record, and an empty dictionary for climate_record\n",
    "    climate_record = {}\n",
    "    aqua_hotspots_record = []\n",
    "    terra_hotspots_record = []\n",
    "    \n",
    "    # Producer 1: Climate topic_name = \"Climate\", [\"producer_id\"] = \"producer1_climate\"\n",
    "    # Producer 2: AQUA topic_name = \"Hotspot_AQUA\", [\"producer_id\"] = \"producer2_hotspot_aqua\"\n",
    "    # Producer 3: TERRA topic_name = \"Hotspot_TERRA\", [\"producer_id\"] = \"producer3_hotspot_terra\"\n",
    "    \n",
    "    # For each item from the data batch from the Kafka stream \n",
    "    for eachdata in range(len(producer_data)): \n",
    "        temp_var = producer_data[eachdata].get(\"value\")\n",
    "        # print(\"eachdata: \", eachdata)\n",
    "        # Convert byte array to string\n",
    "        newdata = temp_var.decode('utf-8')\n",
    "        # Convert string to JSON\n",
    "        produced_data = json.loads(newdata)\n",
    "        print(\"produced_data: \", produced_data)\n",
    "        producer_id = produced_data[\"producer_id\"]\n",
    "\n",
    "        # Sort data depending on the producer_id information\n",
    "        if producer_id == \"producer1_climate\":\n",
    "            climate_record = produced_data\n",
    "        elif producer_id == \"producer2_hotspot_aqua\":\n",
    "            aqua_hotspots_record.append(produced_data)\n",
    "        elif producer_id == \"producer3_hotspot_terra\":\n",
    "            terra_hotspots_record.append(produced_data)\n",
    "\n",
    "    # Analyse hotspots data, find if any are close by & merge\n",
    "    new_hotspots_record = process_hotspots(aqua_hotspots_record, terra_hotspots_record, climate_record)\n",
    "    # Merge hotspots with climate depending if close & label if natural or other\n",
    "    new_climate_record = process_climate(climate_record, new_hotspots_record)\n",
    "\n",
    "    return new_climate_record\n",
    "\n",
    "def process_hotspots(aqua_hotspots_record, terra_hotspots_record, climate_record):\n",
    "    # Initialize empty array for hotspots records from both terra and aqua\n",
    "    hotspots = []\n",
    "    \n",
    "    print(\"climate_record: \", climate_record)\n",
    "    \n",
    "    # Get Climate longitude and latitude\n",
    "    climate_latitude = climate_record.get(\"latitude\")\n",
    "    climate_longitude = climate_record.get(\"longitude\") \n",
    "    \n",
    "    print(\"climate_latitude: \", climate_latitude)\n",
    "    print(\"climate_longitude: \", climate_longitude)\n",
    "    \n",
    "    # Process aqua_hotspots_record\n",
    "    for each_record in aqua_hotspots_record:\n",
    "        if geohash_proximity(each_record, climate_record):\n",
    "            each_record[\"date\"] = climate_record.get(\"date\")\n",
    "            hotspots.append(each_record)\n",
    "            \n",
    "    # Process terra_hotspots_record\n",
    "    for each_record in terra_hotspots_record:\n",
    "        if geohash_proximity(each_record, climate_record):\n",
    "            each_record[\"date\"] = climate_record.get(\"date\")\n",
    "            hotspots.append(each_record)\n",
    "            \n",
    "    return hotspots\n",
    "\n",
    "def process_climate(climate_record, hotspots_record):\n",
    "    # Initialize empty array for fire events records\n",
    "    fire_events = []\n",
    "    for each_record in hotspots_record:\n",
    "        fire_event = process_fire_event(climate_record, each_record)\n",
    "        if fire_event is not None:\n",
    "            fire_events.append(fire_event)\n",
    "    climate_record[\"fire_events\"] = fire_events\n",
    "    return climate_record\n",
    "\n",
    "def process_fire_event(climate_record, hotspots_record):\n",
    "    # Initialize an empty dictionary to store fire event data\n",
    "    fire_happening = {}\n",
    "\n",
    "    # Check if the hotspot is geographically close to the climate data with a precision of 5\n",
    "    if geohash_proximity_5(hotspots_record, climate_record) is True:\n",
    "        \n",
    "        print(\"hotspots_record: \", hotspots_record)\n",
    "        \n",
    "        # Calculate the average surface temperature from both hotspot and climate data\n",
    "        average_temp = (hotspots_record.get(\"surface_temperature_celcius\") + hotspots_record.get(\"surface_temperature_celcius\")) / 2\n",
    "        fire_happening[\"average_surface_temp\"] = average_temp\n",
    "\n",
    "        # Calculate the average confidence level from both hotspot and climate data\n",
    "        average_confidence = (hotspots_record.get(\"confidence\") + hotspots_record.get(\"confidence\")) / 2\n",
    "        fire_happening[\"confidence\"] = average_confidence\n",
    "\n",
    "        # Determine the cause of the fire based on climate conditions\n",
    "        air_temp = climate_record.get(\"air_temperature_celcius\")\n",
    "        solar_irradiance = climate_record.get(\"GHI_w/m2\")\n",
    "        if air_temp > 20 and solar_irradiance > 180:\n",
    "            fire_happening[\"cause\"] = \"natural\"\n",
    "        else:\n",
    "            fire_happening[\"cause\"] = \"others\"\n",
    "        \n",
    "        print(\"fire_happening: \", fire_happening)\n",
    "\n",
    "        # Return the dictionary containing fire event data\n",
    "        return fire_happening\n",
    "    # If the hotspot is not close to the climate data, return None\n",
    "    return None\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
